{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "60aeba0a-ad05-4060-8b27-26d5a98ad960",
      "metadata": {
        "id": "60aeba0a-ad05-4060-8b27-26d5a98ad960"
      },
      "source": [
        "CNN : Convolutional Neural Network it is a type of deep learning model primarly used for preprocessing & analyzing visual data.CNN are particularly effective for tasks like image classification,object detection & image segmentation because they can automatically & adaptively learn spatial heirarchies of features from input images .\n",
        "\n",
        "Application :\n",
        "1.Image Classification\n",
        "->Object Recognition: Identifying objects within an image, such as distinguishing between different animals, vehicles, or everyday items.\n",
        "->Scene Classification: Categorizing an entire scene, such as recognizing different types of landscapes or environments (e.g., beaches, forests, cities).\n",
        "\n",
        "2.Object Detection\n",
        "->Bounding Box Prediction: Identifying and localizing objects within an image by drawing bounding boxes around them.\n",
        "->Face Detection: Recognizing and locating human faces in images or videos.\n",
        "\n",
        "3.Medical Imaging\n",
        "->Disease Diagnosis: Analyzing medical images such as X-rays, MRIs, and CT scans to detect abnormalities, tumors, or other medical conditions.\n",
        "->Histopathology: Examining tissue samples to identify diseases at a cellular level\n",
        "\n",
        "4.Facial Recognition\n",
        "->Authentication Systems: Verifying identities in security systems, smartphones, and other devices.\n",
        "->Emotion Detection: Analyzing facial expressions to determine emotional states.\n",
        "\n",
        "5.Natural Language Processing (NLP)\n",
        "->Image Captioning: Generating descriptive captions for images by combining CNNs with Recurrent Neural Networks (RNNs).\n",
        "->Visual Question Answering: Answering questions about the content of an image.\n",
        "\n",
        "Advantages :\n",
        "1.Automatic Feature Extraction:\n",
        "CNNs automatically learn and extract features from raw images, eliminating the need for manual feature engineering.\n",
        "2.Spatial Hierarchies of Features:\n",
        "Convolutional layers capture spatial hierarchies in images, recognizing patterns and structures at different levels (e.g., edges, textures, objects).\n",
        "3.Translation Invariance:\n",
        "CNNs can recognize objects regardless of their position in the image, making them robust to translations and slight variations.\n",
        "\n",
        "Disadvantages :\n",
        "1.Computationally Intensive:\n",
        "Training CNNs requires significant computational power and memory, especially for deep networks and large datasets.\n",
        "2.Data Requirements:\n",
        "CNNs typically require large amounts of labeled data to train effectively, which can be a limitation in scenarios with limited data availability\n",
        "3.Lack of Interpretability:\n",
        "CNNs are often considered \"black boxes\" because it can be challenging to understand how they make decisions and which features they prioritize."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb9bdf5f-6d43-4cae-b9f1-0156841425bd",
      "metadata": {
        "id": "fb9bdf5f-6d43-4cae-b9f1-0156841425bd"
      },
      "source": [
        "CNN Architecture:\n",
        "\n",
        "1.Input Layer:\n",
        "The input layer takes the raw pixel values of the image. The image dimensions (height, width, and channels) define the input shape.\n",
        "\n",
        "2.Convolutional Layers:\n",
        "These layers apply convolution operations to the input, detecting local patterns such as edges and textures.\n",
        "Each convolutional layer is typically followed by an activation function (e.g., ReLU) to introduce non-linearity.\n",
        "\n",
        "3.Pooling Layers:\n",
        "Pooling layers (e.g., max pooling) reduce the spatial dimensions of the feature maps, retaining important features while reducing computation.They help in making the network invariant to small translations and distortions.\n",
        "\n",
        "4.Fully Connected Layers:\n",
        "These layers connect every neuron in one layer to every neuron in the next layer, similar to a traditional neural network.\n",
        "They aggregate the features learned by convolutional layers to make final predictions.\n",
        "\n",
        "5.Output Layer:\n",
        "The output layer produces the final predictions. For classification tasks, this typically includes a softmax activation function for probability distribution over classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b7a6500-c19d-4f8a-a515-03f88b15850a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b7a6500-c19d-4f8a-a515-03f88b15850a",
        "outputId": "c9e6d0ea-2f63-4825-bf07-b7b6288162b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               6422784   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6518602 (24.87 MB)\n",
            "Trainable params: 6518602 (24.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Additional convolutional and pooling layers\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Flattening the feature maps\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))  # Regularization to prevent overfitting\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (128, 128, 3)  # Example input shape (height, width, channels)\n",
        "num_classes = 10  # Example number of classes\n",
        "model = create_cnn_model(input_shape, num_classes)\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a5089be-aa74-4248-a613-f8708e009744",
      "metadata": {
        "id": "0a5089be-aa74-4248-a613-f8708e009744"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da853a9a-1845-4157-af2b-754931fceae6",
      "metadata": {
        "id": "da853a9a-1845-4157-af2b-754931fceae6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cecc72b-5096-414e-855e-ebecbaa8cf8d",
      "metadata": {
        "id": "5cecc72b-5096-414e-855e-ebecbaa8cf8d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21deab6-e885-4a17-875c-f74c183de5ce",
      "metadata": {
        "id": "f21deab6-e885-4a17-875c-f74c183de5ce"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "201ed610-ffc1-4689-b70e-eb4ebf28bb1a",
      "metadata": {
        "id": "201ed610-ffc1-4689-b70e-eb4ebf28bb1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c615670d-ba7f-44ad-8d01-0192d9955e3e",
      "metadata": {
        "id": "c615670d-ba7f-44ad-8d01-0192d9955e3e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4f2895-72c5-45f3-b28c-bcc5f739bc2c",
      "metadata": {
        "id": "5b4f2895-72c5-45f3-b28c-bcc5f739bc2c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e31a42aa-f97b-4d27-865f-06e21522f6d8",
      "metadata": {
        "id": "e31a42aa-f97b-4d27-865f-06e21522f6d8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c928d63e-7b51-4e00-a0aa-f203a4b7378b",
      "metadata": {
        "id": "c928d63e-7b51-4e00-a0aa-f203a4b7378b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6739f22e-32de-450a-af51-e8977b34ec82",
      "metadata": {
        "id": "6739f22e-32de-450a-af51-e8977b34ec82"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}